<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Yicong Zheng</title>
    <link>https://zycyc.github.io/projects/</link>
    <description>Recent content in Projects on Yicong Zheng</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://zycyc.github.io/projects/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Photography</title>
      <link>https://zycyc.github.io/projects/photography/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zycyc.github.io/projects/photography/</guid>
      <description>I enjoy taking photos everywhere I go.
They form the trajectory of my life and more importantly, my personal visual diary.
My cameras include Nikon D5200, iPhone 7, iPhone SE (emeritus) and Mi 4 (emeritus).</description>
    </item>
    
    <item>
      <title>Musical Memory</title>
      <link>https://zycyc.github.io/projects/mm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zycyc.github.io/projects/mm/</guid>
      <description>How does human learn music? The one simple answer will be repeatedly listening, but what&amp;rsquo;s the underlying neural mechanism that supports this learning process? Better memory performance is predicted by higher representational similarity between encoding and retrieval (Xue, 2010), is memory of music the same? Beyond this question, I also want to find out how cortex and hippocampus represents musical features like tempo, pitch, rhythm, and how these two representation interact to depict music learning curve.</description>
    </item>
    
    <item>
      <title>Serial Dependence</title>
      <link>https://zycyc.github.io/projects/sd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zycyc.github.io/projects/sd/</guid>
      <description>We tend to perceive the world around us as stable in space and time, a study by Fischer and Whitney (2014) suggests that human visual perception is serially dependent, using both prior and present input to inform perception at the present moment. Specifically, perceived orientation in an orientation judgment task is likely biased towards previously seen stimuli.
Currently I&amp;rsquo;m doing replication and relevant experiment both on-line and off-line with Dr. Mauro Manassi and Prof.</description>
    </item>
    
  </channel>
</rss>